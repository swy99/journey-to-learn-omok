{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mock5 import Mock5\n",
    "from mock5.analysis import Analysis as M5Analysis\n",
    "import mock5.agent_random as m5rand\n",
    "import mock5.agent_analysis_based as m5aa\n",
    "import mock5.agent_ad as m5ad\n",
    "import mock5.agent_pt as m5pt\n",
    "import mock5.agent_df as m5df\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"Device: {}\".format(device))\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.autograd.set_detect_anomaly(False)\n",
    "\n",
    "print(\"cudnn: {} (det {}; bench {})\".format(\n",
    "    torch.backends.cudnn.enabled,\n",
    "    torch.backends.cudnn.deterministic,\n",
    "    torch.backends.cudnn.benchmark))\n",
    "print(\"OpenMP: {}\".format(torch.backends.openmp.is_available()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Board Size\n",
    "W = 15\n",
    "H = W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_name(fn):\n",
    "  if hasattr(fn, 'name'): return fn.name\n",
    "  else: return repr(fn)\n",
    "  \n",
    "def agent(pi, epsilon=0):\n",
    "  # pi must return array of non-negative values\n",
    "  def c(game):\n",
    "    w, h = game.width, game.height\n",
    "    m, p = np.ones(h * w), np.array(pi(game))\n",
    "    for i in range(h * w):\n",
    "      if game.board[i] != 0: m[i], p[i] = 0, 0\n",
    "    s = p.sum()\n",
    "    if np.random.uniform() < epsilon or s == 0:\n",
    "      s = m.sum()\n",
    "      if s == 0: return None, None # Cannot do anything\n",
    "      else: idx = np.random.choice(h * w, p=(m / s))\n",
    "    else: idx = np.random.choice(h * w, p=(p / s))\n",
    "    return idx // w, idx % w\n",
    "  c.name = 'stochastic({})'.format(fn_name(pi))\n",
    "  return c\n",
    "\n",
    "def softmax(arr, tau=1.0):\n",
    "  arr = np.array(arr, dtype=np.float64)\n",
    "  arr /= tau\n",
    "  m = max(arr)\n",
    "  z = np.exp(arr - m)\n",
    "  return z / z.sum()\n",
    "\n",
    "def pt_softmax(policy, tau=1.0):\n",
    "  def p(game):\n",
    "    p = policy(game)\n",
    "    return softmax(p, tau=tau)\n",
    "  p.name = 'pt_softmax({},tau={})'.format(fn_name(policy), tau)\n",
    "  return p\n",
    "\n",
    "def pt_norm(policy):\n",
    "  def p(game):\n",
    "    p = policy(game)\n",
    "    return p / p.max()\n",
    "  p.name = 'pt_norm({})'.format(fn_name(policy))\n",
    "  return p\n",
    "\n",
    "def policy_uniform(game):\n",
    "  return np.ones(game.height * game.width)\n",
    "policy_uniform.name = 'uniform'\n",
    "\n",
    "def agent_mixed(game):\n",
    "  a = np.random.uniform()\n",
    "  if a < 0.4: return m5aa.agent(game)\n",
    "  elif a < 0.8: return m5ad.agent(game)\n",
    "  elif a < 0.9: return m5pt.agent(game)\n",
    "  else: return m5df.agent(game)\n",
    "agent_mixed.name = 'agent-mixed-analysis-based'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "  def forward(self, x):\n",
    "    if len(x.shape) == 3: return x.view(-1)\n",
    "    else: return x.flatten(1, -1)\n",
    "\n",
    "class Block2(nn.Module):\n",
    "  def __init__(self, ch, int_ch, ker):\n",
    "    super().__init__()\n",
    "    self.seq = nn.Sequential(\n",
    "      nn.Conv2d(ch, int_ch, ker, padding='same'),\n",
    "      nn.BatchNorm2d(int_ch),\n",
    "      nn.Sigmoid(),\n",
    "      nn.Conv2d(int_ch, ch, ker, padding='same'),\n",
    "      nn.BatchNorm2d(ch))\n",
    "  def forward(self, x):\n",
    "    y_0 = self.seq(x)\n",
    "    inp = x + y_0\n",
    "    return torch.sigmoid(inp)\n",
    "\n",
    "class Block1(nn.Module):\n",
    "  def __init__(self, ch, int_ch, ker):\n",
    "    super().__init__()\n",
    "    self.seq = nn.Sequential(\n",
    "      nn.Conv2d(ch, int_ch, ker, padding='same'),\n",
    "      nn.GELU(),\n",
    "      nn.Conv2d(int_ch, ch, ker, padding='same'))\n",
    "  def forward(self, x):\n",
    "    y_0 = self.seq(x)\n",
    "    return nn.functional.gelu(x + y_0)\n",
    "\n",
    "class Value(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.seq = nn.Sequential(\n",
    "      nn.Conv2d(2, 128, 3, padding='same'),\n",
    "      nn.BatchNorm2d(128),\n",
    "      nn.Sigmoid(),\n",
    "      Block2(128, 128, 3),\n",
    "      Block2(128, 128, 3),\n",
    "      Block2(128, 128, 3),\n",
    "      nn.Conv2d(128, 1, 1, padding='same'),\n",
    "      nn.BatchNorm2d(1),\n",
    "      nn.Sigmoid(),\n",
    "      # Flatten\n",
    "      Flatten(),\n",
    "      # Winrate\n",
    "      nn.Linear(H*W,1))\n",
    "      \n",
    "  def forward(self, x):\n",
    "    return self.seq(x)\n",
    "\n",
    "class Policy(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.seq = nn.Sequential(\n",
    "      nn.Conv2d(2, 128, 3, padding='same'),\n",
    "      nn.GELU(),\n",
    "      Block1(128, 128, 3),\n",
    "      Block1(128, 128, 3),\n",
    "      Block1(128, 128, 3),\n",
    "      nn.Conv2d(128, 1, 5, padding='same'),\n",
    "      nn.GELU(),\n",
    "      # Flatten\n",
    "      Flatten(),\n",
    "      # Softmax\n",
    "      nn.LogSoftmax(dim=-1))\n",
    "\n",
    "  def forward(self, x):\n",
    "    return self.seq(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def game_to_tensor(game):\n",
    "  t = torch.zeros(2, game.height * game.width, dtype=torch.float)\n",
    "  for i in range(game.height * game.width):\n",
    "    b = game.board[i]\n",
    "    if b == 1: t[0][i] = 1.0\n",
    "    elif b == 2: t[1][i] = 1.0\n",
    "  return t.view(2, game.height, game.width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_model(net):\n",
    "  def c(game):\n",
    "    X = game_to_tensor(game).to(device)\n",
    "    with torch.no_grad():\n",
    "      p = torch.exp(net(X))\n",
    "    arr = p.squeeze().to('cpu').numpy()\n",
    "    return arr\n",
    "  c.name = 'model({:x})'.format(id(net))\n",
    "  return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_game_replay(Xs, Vs, nsample, game, result):\n",
    "  # Append to Batch\n",
    "  exch = game.exchanged\n",
    "  if result == 1:\n",
    "    v = 1 # 흑 승리시 1\n",
    "  elif result == 2:\n",
    "    v = 0 # 백 승리시 0\n",
    "  else: v = 0.5 # 무승부\n",
    "  if exch:\n",
    "    v = 1-v\n",
    "  \n",
    "  X = []\n",
    "  V = []\n",
    "  for f in range(2):\n",
    "    for r in range(4):\n",
    "      g = game.replay(angle=r, flip=f)\n",
    "      while len(g.history) > 0:\n",
    "        g.undo()\n",
    "        X.append(game_to_tensor(g))\n",
    "        V.append(v)\n",
    "  if len(X) < nsample:\n",
    "    Xs += X\n",
    "    Vs += V\n",
    "  else:\n",
    "    Xs += random.sample(X, nsample)\n",
    "    Vs += random.sample(V, nsample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_episode_by_play(\n",
    "    agent1,\n",
    "    agent2\n",
    "):\n",
    "  def generator(Xs, Vs, nsample):\n",
    "    # Run Game\n",
    "    game = Mock5(H, W)\n",
    "    result = game.play(agent1, agent2,\n",
    "      print_intermediate_state=False, print_messages=False)\n",
    "    # Make reward\n",
    "    append_game_replay(Xs, Vs, nsample, game, result)\n",
    "    return 1\n",
    "  return generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_to_game(X):\n",
    "  board = []\n",
    "  for i in range(H):\n",
    "    for j in range(W):\n",
    "      if(X[0][i][j] == 1):\n",
    "        board.append(1)\n",
    "      elif(X[1][i][j] == 1):\n",
    "        board.append(2)\n",
    "      else:\n",
    "        board.append(0)\n",
    "  return Mock5(H,W,board=board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "class Epi_generator(threading.Thread):\n",
    "    def __init__(self, func, Xs, Vs, gamma):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "        self.Xs = Xs\n",
    "        self.Vs = Vs\n",
    "        self.gamma = gamma\n",
    "        self.cnt == 0\n",
    "\n",
    "    def run(self):\n",
    "        while len(self.Xs) < 50 and cnt < 100000:\n",
    "            self.func(self.Xs,self.Vs,self.gamma)\n",
    "            cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn(\n",
    "    opt,\n",
    "    n_step,\n",
    "    gen_episode, #: take (Xs, Vs, nsample)\n",
    "    n_epoch,\n",
    "    nsample,\n",
    "    batch_size,\n",
    "    interval_stat,\n",
    "    interval_loss,\n",
    "    filename\n",
    "):\n",
    "  Xs, Vs = [], []\n",
    "  step = 0\n",
    "  global loss_list, avgloss\n",
    "  avgloss = 0\n",
    "  cnt = 0\n",
    "  while step < n_step:\n",
    "    # Generate episode\n",
    "    if len(Xs) < batch_size:\n",
    "      def load(Xs,Vs,filename):\n",
    "        if not os.path.exists(filename):\n",
    "          return\n",
    "        while True:\n",
    "          error = 0\n",
    "          try:\n",
    "            if not datetime.datetime.now().time().second % 20 > 7 : return\n",
    "            [Xo,Vo] = torch.load(filename)\n",
    "            break\n",
    "          except:\n",
    "            error += 1\n",
    "          if error > 10:\n",
    "            print(error)\n",
    "            exit()\n",
    "        while True:\n",
    "          error = 0\n",
    "          try:\n",
    "            if not datetime.datetime.now().time().second % 20 > 7 : return\n",
    "            torch.save([[],[]],filename)\n",
    "            break\n",
    "          except:\n",
    "            error += 1\n",
    "          if error > 10:\n",
    "            print(error)\n",
    "            exit()\n",
    "        Xs.extend(Xo)\n",
    "        Vs.extend(Vo)\n",
    "      load(Xs,Vs,\"21_kibo.1\")\n",
    "      load(Xs,Vs,\"21_kibo.2\")\n",
    "      load(Xs,Vs,\"21_kibo.3\")\n",
    "      load(Xs,Vs,\"21_kibo.4\")\n",
    "    # If batch is full enough, perform gradient ascent\n",
    "    if len(Xs) >= batch_size:\n",
    "      step += 1\n",
    "      # Tensorify\n",
    "      X = []\n",
    "      V = []\n",
    "      for __ in range(batch_size):\n",
    "        X.append(Xs.pop(0))\n",
    "        V.append(Vs.pop(0))\n",
    "      X = torch.stack(X).to(device)\n",
    "      V = torch.Tensor(V).to(device)\n",
    "      # Learn\n",
    "      for e in range(n_epoch):\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        v_pred = value(X)\n",
    "        loss = ((v_pred-V)**2).mean()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        avgloss += float(loss)/interval_loss\n",
    "        cnt += 1\n",
    "        if cnt >= interval_loss:\n",
    "          loss_list.append(avgloss)\n",
    "          cnt = 0\n",
    "          avgloss = 0\n",
    "      \n",
    "      # Print status and evaluate\n",
    "      if step % interval_stat == 0:\n",
    "        try:\n",
    "          torch.save(value, filename)\n",
    "        except:\n",
    "          try:\n",
    "            torch.save(value, filename)\n",
    "          except:\n",
    "            try:\n",
    "              torch.save(value, filename)\n",
    "            except:\n",
    "              print(\"failed\")\n",
    "            \n",
    "        print(\"Step #\", step, \" loss \", round(float(loss),4))\n",
    "    else:\n",
    "      gen_episode(Xs, Vs, nsample)\n",
    "  \n",
    "  plt.plot(100 * np.arange(0,len(loss_list)),np.array(loss_list))\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "global policy, value\n",
    "filename = \"21_value.save\"\n",
    "\n",
    "def run():\n",
    "  global value, policy\n",
    "  if os.path.exists(filename):\n",
    "    value = torch.load(filename)\n",
    "  else:\n",
    "    value = Value().to(device)\n",
    "\n",
    "  policy = Policy().to(device)\n",
    "  f = torch.load('19_weight_10hr')[\"network state dict\"]\n",
    "  policy.load_state_dict(f)\n",
    "                    \n",
    "  opt = optim.SGD(value.parameters(),\n",
    "                    lr=3e-3,\n",
    "                    momentum=0.8,\n",
    "                    weight_decay=1e-5)\n",
    "\n",
    "  agent1 = agent(policy_model(policy))\n",
    "  agent2 = agent(policy_model(policy))\n",
    "  \n",
    "  \n",
    "  learn(\n",
    "      opt = opt,\n",
    "      n_step = 10000,\n",
    "      gen_episode = gen_episode_by_play(agent1, agent2),\n",
    "      n_epoch = 1,\n",
    "      nsample = 2,\n",
    "      batch_size = 1024,\n",
    "      interval_stat = 10,\n",
    "      interval_loss = 2,\n",
    "      filename = filename)\n",
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(2 * np.arange(0,len(loss_list)),np.array(loss_list))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1003aba94e8b49eb6577752c067d2ddea1ccd0c689ae55370a86babf6ba72f76"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
