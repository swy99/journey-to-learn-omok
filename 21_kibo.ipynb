{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "cudnn: True (det False; bench True)\n",
      "OpenMP: True\n"
     ]
    }
   ],
   "source": [
    "from mock5 import Mock5\n",
    "from mock5.analysis import Analysis as M5Analysis\n",
    "import mock5.agent_random as m5rand\n",
    "import mock5.agent_analysis_based as m5aa\n",
    "import mock5.agent_ad as m5ad\n",
    "import mock5.agent_pt as m5pt\n",
    "import mock5.agent_df as m5df\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "filename = \"21_kibo.1\"\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"Device: {}\".format(device))\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.autograd.set_detect_anomaly(False)\n",
    "\n",
    "print(\"cudnn: {} (det {}; bench {})\".format(\n",
    "    torch.backends.cudnn.enabled,\n",
    "    torch.backends.cudnn.deterministic,\n",
    "    torch.backends.cudnn.benchmark))\n",
    "print(\"OpenMP: {}\".format(torch.backends.openmp.is_available()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Board Size\n",
    "W = 15\n",
    "H = W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_name(fn):\n",
    "  if hasattr(fn, 'name'): return fn.name\n",
    "  else: return repr(fn)\n",
    "  \n",
    "def agent(pi, epsilon=0):\n",
    "  # pi must return array of non-negative values\n",
    "  def c(game):\n",
    "    w, h = game.width, game.height\n",
    "    m, p = np.ones(h * w), np.array(pi(game))\n",
    "    for i in range(h * w):\n",
    "      if game.board[i] != 0: m[i], p[i] = 0, 0\n",
    "    s = p.sum()\n",
    "    if np.random.uniform() < epsilon or s == 0:\n",
    "      s = m.sum()\n",
    "      if s == 0: return None, None # Cannot do anything\n",
    "      else: idx = np.random.choice(h * w, p=(m / s))\n",
    "    else: idx = np.random.choice(h * w, p=(p / s))\n",
    "    return idx // w, idx % w\n",
    "  c.name = 'stochastic({})'.format(fn_name(pi))\n",
    "  return c\n",
    "\n",
    "def softmax(arr, tau=1.0):\n",
    "  arr = np.array(arr, dtype=np.float64)\n",
    "  arr /= tau\n",
    "  m = max(arr)\n",
    "  z = np.exp(arr - m)\n",
    "  return z / z.sum()\n",
    "\n",
    "def pt_softmax(policy, tau=1.0):\n",
    "  def p(game):\n",
    "    p = policy(game)\n",
    "    return softmax(p, tau=tau)\n",
    "  p.name = 'pt_softmax({},tau={})'.format(fn_name(policy), tau)\n",
    "  return p\n",
    "\n",
    "def pt_norm(policy):\n",
    "  def p(game):\n",
    "    p = policy(game)\n",
    "    return p / p.max()\n",
    "  p.name = 'pt_norm({})'.format(fn_name(policy))\n",
    "  return p\n",
    "\n",
    "def policy_uniform(game):\n",
    "  return np.ones(game.height * game.width)\n",
    "policy_uniform.name = 'uniform'\n",
    "\n",
    "def agent_mixed(game):\n",
    "  a = np.random.uniform()\n",
    "  if a < 0.4: return m5aa.agent(game)\n",
    "  elif a < 0.8: return m5ad.agent(game)\n",
    "  elif a < 0.9: return m5pt.agent(game)\n",
    "  else: return m5df.agent(game)\n",
    "agent_mixed.name = 'agent-mixed-analysis-based'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "  def forward(self, x):\n",
    "    if len(x.shape) == 3: return x.view(-1)\n",
    "    else: return x.flatten(1, -1)\n",
    "\n",
    "class Block2(nn.Module):\n",
    "  def __init__(self, ch, int_ch, ker):\n",
    "    super().__init__()\n",
    "    self.seq = nn.Sequential(\n",
    "      nn.Conv2d(ch, int_ch, ker, padding='same'),\n",
    "      nn.BatchNorm2d(int_ch),\n",
    "      nn.Sigmoid(),\n",
    "      nn.Conv2d(int_ch, ch, ker, padding='same'),\n",
    "      nn.BatchNorm2d(ch))\n",
    "  def forward(self, x):\n",
    "    y_0 = self.seq(x)\n",
    "    inp = x + y_0\n",
    "    return torch.sigmoid(inp)\n",
    "\n",
    "class Block1(nn.Module):\n",
    "  def __init__(self, ch, int_ch, ker):\n",
    "    super().__init__()\n",
    "    self.seq = nn.Sequential(\n",
    "      nn.Conv2d(ch, int_ch, ker, padding='same'),\n",
    "      nn.GELU(),\n",
    "      nn.Conv2d(int_ch, ch, ker, padding='same'))\n",
    "  def forward(self, x):\n",
    "    y_0 = self.seq(x)\n",
    "    return nn.functional.gelu(x + y_0)\n",
    "\n",
    "class Value(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.seq = nn.Sequential(\n",
    "      nn.Conv2d(2, 128, 3, padding='same'),\n",
    "      nn.BatchNorm2d(128),\n",
    "      nn.Sigmoid(),\n",
    "      Block2(128, 128, 3),\n",
    "      Block2(128, 128, 3),\n",
    "      Block2(128, 128, 3),\n",
    "      nn.Conv2d(128, 1, 1, padding='same'),\n",
    "      nn.BatchNorm2d(1),\n",
    "      nn.Sigmoid(),\n",
    "      # Flatten\n",
    "      Flatten(),\n",
    "      # Winrate\n",
    "      nn.Linear(H*W,1))\n",
    "      \n",
    "  def forward(self, x):\n",
    "    return self.seq(x)\n",
    "\n",
    "class Policy(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.seq = nn.Sequential(\n",
    "      nn.Conv2d(2, 128, 3, padding='same'),\n",
    "      nn.GELU(),\n",
    "      Block1(128, 128, 3),\n",
    "      Block1(128, 128, 3),\n",
    "      Block1(128, 128, 3),\n",
    "      nn.Conv2d(128, 1, 5, padding='same'),\n",
    "      nn.GELU(),\n",
    "      # Flatten\n",
    "      Flatten(),\n",
    "      # Softmax\n",
    "      nn.LogSoftmax(dim=-1))\n",
    "\n",
    "  def forward(self, x):\n",
    "    return self.seq(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def game_to_tensor(game):\n",
    "  t = torch.zeros(2, game.height * game.width, dtype=torch.float)\n",
    "  for i in range(game.height * game.width):\n",
    "    b = game.board[i]\n",
    "    if b == 1: t[0][i] = 1.0\n",
    "    elif b == 2: t[1][i] = 1.0\n",
    "  return t.view(2, game.height, game.width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_model(net):\n",
    "  def c(game):\n",
    "    X = game_to_tensor(game).to(device)\n",
    "    with torch.no_grad():\n",
    "      p = torch.exp(net(X))\n",
    "    arr = p.squeeze().to('cpu').numpy()\n",
    "    return arr\n",
    "  c.name = 'model({:x})'.format(id(net))\n",
    "  return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_game_replay(Xs, Vs, nsample, game, result):\n",
    "  # Append to Batch\n",
    "  exch = game.exchanged\n",
    "  if result == 1:\n",
    "    v = 1 # 흑 승리시 1\n",
    "  elif result == 2:\n",
    "    v = 0 # 백 승리시 0\n",
    "  else: v = 0.5 # 무승부\n",
    "  if exch:\n",
    "    v = 1-v\n",
    "  \n",
    "  X = []\n",
    "  V = []\n",
    "  for f in range(2):\n",
    "    for r in range(4):\n",
    "      g = game.replay(angle=r, flip=f)\n",
    "      while len(g.history) > 0:\n",
    "        g.undo()\n",
    "        X.append(game_to_tensor(g))\n",
    "        V.append(v)\n",
    "  if len(X) < nsample:\n",
    "    Xs += X\n",
    "    Vs += V\n",
    "  else:\n",
    "    Xs += random.sample(X, nsample)\n",
    "    Vs += random.sample(V, nsample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_episode_by_play(\n",
    "    agent1,\n",
    "    agent2\n",
    "):\n",
    "  def generator(Xs, Vs, nsample):\n",
    "    # Run Game\n",
    "    game = Mock5(H, W)\n",
    "    result = game.play(agent1, agent2,\n",
    "      print_intermediate_state=False, print_messages=False)\n",
    "    # Make reward\n",
    "    append_game_replay(Xs, Vs, nsample, game, result)\n",
    "    return 1\n",
    "  return generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_to_game(X):\n",
    "  board = []\n",
    "  for i in range(H):\n",
    "    for j in range(W):\n",
    "      if(X[0][i][j] == 1):\n",
    "        board.append(1)\n",
    "      elif(X[1][i][j] == 1):\n",
    "        board.append(2)\n",
    "      else:\n",
    "        board.append(0)\n",
    "  return Mock5(H,W,board=board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "class Epi_generator(threading.Thread):\n",
    "    def __init__(self, func, Xs, Vs, gamma):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "        self.Xs = Xs\n",
    "        self.Vs = Vs\n",
    "        self.gamma = gamma\n",
    "        self.cnt == 0\n",
    "\n",
    "    def run(self):\n",
    "        while len(self.Xs) < 50 and cnt < 100000:\n",
    "            self.func(self.Xs,self.Vs,self.gamma)\n",
    "            cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn(\n",
    "    opt,\n",
    "    n_step,\n",
    "    gen_episode, #: take (Xs, Vs, nsample)\n",
    "    n_epoch,\n",
    "    nsample,\n",
    "    batch_size,\n",
    "    interval_stat,\n",
    "    filename\n",
    "):\n",
    "  Xs, Vs = [], []\n",
    "  step = 0\n",
    "  global loss_list, loss_10\n",
    "  loss_10 = 0\n",
    "  cnt = 0\n",
    "  while step < n_step:\n",
    "    step+=1\n",
    "    # Generate episode\n",
    "    gen_episode(Xs, Vs, nsample)\n",
    "    # If batch is full enough, perform gradient ascent\n",
    "    # Print status and evaluate\n",
    "    def save(Xs, Vs, f):\n",
    "      if not os.path.exists(f):\n",
    "        while True:\n",
    "          error = 0\n",
    "          try:\n",
    "            if not datetime.datetime.now().time().second % 20 < 13 : return\n",
    "            torch.save([Xs,Vs],f)\n",
    "            Xs, Vs = [], []\n",
    "            break\n",
    "          except:\n",
    "            error += 1\n",
    "          if error > 10:\n",
    "            print(error)\n",
    "            exit()\n",
    "      while True:\n",
    "        error = 0\n",
    "        try:\n",
    "          if not datetime.datetime.now().time().second % 20 < 13 : return\n",
    "          [Xo,Vo] = torch.load(f)\n",
    "          break\n",
    "        except:\n",
    "          error += 1\n",
    "        if error > 10:\n",
    "          print(error)\n",
    "          exit()\n",
    "      while True:\n",
    "        error = 0\n",
    "        try:\n",
    "          if not datetime.datetime.now().time().second % 20 < 13 : return\n",
    "          torch.save([Xo+Xs,Vo+Vs],f)\n",
    "          Xs, Vs = [], []\n",
    "          break\n",
    "        except:\n",
    "          error += 1\n",
    "        if error > 10:\n",
    "          print(error)\n",
    "          exit()\n",
    "      save(Xs, Vs, filename)\n",
    "      print(\"Step #\", step)\n",
    "  \n",
    "  plt.plot(100 * np.arange(0,len(loss_list)),np.array(loss_list))\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step # 1\n",
      "Step # 2\n",
      "Step # 3\n",
      "Step # 4\n",
      "Step # 5\n",
      "Step # 6\n",
      "Step # 7\n",
      "Step # 8\n",
      "Step # 22\n",
      "Step # 23\n",
      "Step # 24\n",
      "Step # 25\n",
      "Step # 26\n",
      "Step # 27\n",
      "Step # 28\n",
      "Step # 29\n",
      "Step # 30\n",
      "Step # 31\n",
      "Step # 46\n",
      "Step # 47\n",
      "Step # 48\n",
      "Step # 49\n",
      "Step # 50\n",
      "Step # 51\n",
      "Step # 52\n",
      "Step # 53\n",
      "Step # 54\n",
      "Step # 55\n",
      "Step # 56\n",
      "Step # 57\n",
      "Step # 58\n",
      "Step # 59\n",
      "Step # 60\n",
      "Step # 61\n",
      "Step # 62\n",
      "Step # 63\n",
      "Step # 76\n",
      "Step # 77\n",
      "Step # 78\n",
      "Step # 89\n",
      "Step # 90\n",
      "Step # 91\n",
      "Step # 92\n",
      "Step # 93\n",
      "Step # 94\n",
      "Step # 95\n",
      "Step # 96\n",
      "Step # 97\n",
      "Step # 98\n",
      "Step # 99\n",
      "Step # 100\n",
      "Step # 105\n",
      "Step # 106\n",
      "Step # 107\n",
      "Step # 108\n",
      "Step # 109\n",
      "Step # 110\n",
      "Step # 111\n",
      "Step # 112\n",
      "Step # 115\n",
      "Step # 116\n",
      "Step # 117\n",
      "Step # 118\n",
      "Step # 119\n",
      "Step # 120\n",
      "Step # 133\n",
      "Step # 134\n",
      "Step # 135\n",
      "Step # 136\n",
      "Step # 137\n",
      "Step # 138\n",
      "Step # 139\n",
      "Step # 140\n",
      "Step # 150\n",
      "Step # 151\n",
      "Step # 152\n",
      "Step # 153\n",
      "Step # 154\n",
      "Step # 155\n",
      "Step # 156\n",
      "Step # 157\n",
      "Step # 158\n",
      "Step # 159\n",
      "Step # 170\n",
      "Step # 171\n",
      "Step # 172\n",
      "Step # 173\n",
      "Step # 174\n",
      "Step # 175\n",
      "Step # 183\n",
      "Step # 184\n",
      "Step # 185\n",
      "Step # 186\n",
      "Step # 203\n",
      "Step # 204\n",
      "Step # 205\n",
      "Step # 206\n",
      "Step # 217\n",
      "Step # 218\n",
      "Step # 219\n",
      "Step # 227\n",
      "Step # 228\n",
      "Step # 229\n",
      "Step # 230\n",
      "Step # 245\n",
      "Step # 246\n",
      "Step # 247\n",
      "Step # 248\n",
      "Step # 256\n",
      "Step # 257\n",
      "Step # 258\n",
      "Step # 259\n",
      "Step # 260\n",
      "Step # 261\n",
      "Step # 264\n",
      "Step # 265\n",
      "Step # 266\n",
      "Step # 271\n",
      "Step # 272\n",
      "Step # 273\n",
      "Step # 274\n",
      "Step # 275\n",
      "Step # 283\n",
      "Step # 284\n",
      "Step # 287\n",
      "Step # 293\n",
      "Step # 294\n",
      "Step # 298\n",
      "Step # 299\n",
      "Step # 300\n",
      "Step # 301\n",
      "Step # 302\n",
      "Step # 303\n",
      "Step # 304\n",
      "Step # 305\n",
      "Step # 315\n",
      "Step # 316\n",
      "Step # 317\n",
      "Step # 321\n",
      "Step # 322\n",
      "Step # 323\n",
      "Step # 324\n",
      "Step # 325\n",
      "Step # 326\n",
      "Step # 327\n",
      "Step # 328\n",
      "Step # 333\n",
      "Step # 334\n",
      "Step # 338\n",
      "Step # 339\n",
      "Step # 343\n",
      "Step # 344\n",
      "Step # 345\n",
      "Step # 346\n",
      "Step # 353\n",
      "Step # 354\n",
      "Step # 355\n",
      "Step # 357\n",
      "Step # 358\n",
      "Step # 361\n",
      "Step # 362\n",
      "Step # 363\n",
      "Step # 373\n",
      "Step # 374\n",
      "Step # 381\n",
      "Step # 384\n",
      "Step # 385\n",
      "Step # 386\n",
      "Step # 387\n",
      "Step # 388\n",
      "Step # 389\n",
      "Step # 397\n",
      "Step # 398\n",
      "Step # 399\n",
      "Step # 400\n",
      "Step # 401\n",
      "Step # 402\n",
      "Step # 410\n",
      "Step # 415\n",
      "Step # 416\n",
      "Step # 417\n",
      "Step # 418\n",
      "Step # 419\n",
      "Step # 429\n",
      "Step # 430\n",
      "Step # 431\n",
      "Step # 437\n",
      "Step # 438\n",
      "Step # 439\n",
      "Step # 440\n",
      "Step # 444\n",
      "Step # 445\n",
      "Step # 446\n",
      "Step # 447\n",
      "Step # 453\n",
      "Step # 454\n",
      "Step # 455\n",
      "Step # 461\n",
      "Step # 462\n",
      "Step # 463\n",
      "Step # 464\n",
      "Step # 465\n",
      "Step # 466\n",
      "Step # 469\n",
      "Step # 474\n",
      "Step # 475\n",
      "Step # 476\n",
      "Step # 477\n",
      "Step # 480\n",
      "Step # 481\n",
      "Step # 482\n",
      "Step # 483\n",
      "Step # 484\n",
      "Step # 486\n",
      "Step # 487\n",
      "Step # 494\n",
      "Step # 495\n",
      "Step # 496\n",
      "Step # 499\n",
      "Step # 500\n",
      "Step # 506\n",
      "Step # 507\n",
      "Step # 508\n",
      "Step # 509\n",
      "Step # 511\n",
      "Step # 512\n",
      "Step # 513\n",
      "Step # 514\n",
      "Step # 519\n",
      "Step # 524\n",
      "Step # 528\n",
      "Step # 529\n",
      "Step # 530\n",
      "Step # 531\n",
      "Step # 536\n",
      "Step # 537\n",
      "Step # 538\n",
      "Step # 539\n",
      "Step # 541\n",
      "Step # 542\n",
      "Step # 544\n",
      "Step # 545\n",
      "Step # 546\n",
      "Step # 547\n",
      "Step # 548\n",
      "Step # 553\n",
      "Step # 554\n",
      "Step # 556\n",
      "Step # 557\n",
      "Step # 559\n",
      "Step # 560\n",
      "Step # 561\n",
      "Step # 564\n",
      "Step # 565\n",
      "Step # 566\n",
      "Step # 573\n",
      "Step # 574\n",
      "Step # 575\n",
      "Step # 576\n",
      "Step # 577\n",
      "Step # 583\n",
      "Step # 584\n",
      "Step # 588\n",
      "Step # 593\n",
      "Step # 594\n",
      "Step # 595\n",
      "Step # 596\n",
      "Step # 606\n",
      "Step # 607\n",
      "Step # 608\n",
      "Step # 613\n",
      "Step # 614\n",
      "Step # 621\n",
      "Step # 622\n",
      "Step # 623\n",
      "Step # 626\n",
      "Step # 627\n",
      "Step # 628\n",
      "Step # 638\n",
      "Step # 639\n",
      "Step # 640\n",
      "Step # 642\n",
      "Step # 643\n",
      "Step # 644\n",
      "Step # 645\n",
      "Step # 648\n",
      "Step # 652\n",
      "Step # 653\n",
      "Step # 654\n",
      "Step # 655\n",
      "Step # 665\n",
      "Step # 666\n",
      "Step # 667\n",
      "Step # 680\n",
      "Step # 681\n",
      "Step # 682\n",
      "Step # 684\n",
      "Step # 687\n",
      "Step # 688\n",
      "Step # 691\n",
      "Step # 692\n",
      "Step # 693\n",
      "Step # 695\n",
      "Step # 696\n",
      "Step # 699\n",
      "Step # 700\n",
      "Step # 704\n",
      "Step # 708\n",
      "Step # 709\n",
      "Step # 710\n",
      "Step # 711\n",
      "Step # 712\n",
      "Step # 718\n",
      "Step # 719\n",
      "Step # 720\n",
      "Step # 721\n",
      "Step # 723\n",
      "Step # 724\n",
      "Step # 725\n",
      "Step # 727\n",
      "Step # 733\n",
      "Step # 734\n",
      "Step # 735\n",
      "Step # 738\n",
      "Step # 740\n",
      "Step # 745\n",
      "Step # 746\n",
      "Step # 747\n",
      "Step # 756\n",
      "Step # 758\n",
      "Step # 759\n",
      "Step # 760\n",
      "Step # 763\n",
      "Step # 764\n",
      "Step # 765\n",
      "Step # 766\n",
      "Step # 769\n",
      "Step # 770\n",
      "Step # 773\n",
      "Step # 774\n",
      "Step # 777\n",
      "Step # 781\n",
      "Step # 782\n",
      "Step # 785\n",
      "Step # 786\n",
      "Step # 787\n",
      "Step # 791\n",
      "Step # 792\n",
      "Step # 793\n",
      "Step # 797\n",
      "Step # 798\n",
      "Step # 802\n",
      "Step # 803\n",
      "Step # 804\n",
      "Step # 807\n",
      "Step # 808\n",
      "Step # 809\n",
      "Step # 815\n",
      "Step # 816\n",
      "Step # 827\n",
      "Step # 828\n",
      "Step # 829\n",
      "Step # 830\n",
      "Step # 839\n",
      "Step # 840\n",
      "Step # 845\n",
      "Step # 848\n",
      "Step # 849\n",
      "Step # 850\n",
      "Step # 853\n",
      "Step # 854\n",
      "Step # 855\n",
      "Step # 857\n",
      "Step # 858\n",
      "Step # 861\n",
      "Step # 867\n",
      "Step # 871\n",
      "Step # 872\n",
      "Step # 878\n",
      "Step # 879\n",
      "Step # 881\n",
      "Step # 882\n",
      "Step # 883\n",
      "Step # 889\n",
      "Step # 890\n",
      "Step # 893\n",
      "Step # 894\n",
      "Step # 895\n",
      "Step # 897\n",
      "Step # 899\n",
      "Step # 900\n",
      "Step # 906\n",
      "Step # 907\n",
      "Step # 909\n",
      "Step # 910\n",
      "Step # 912\n",
      "Step # 915\n",
      "Step # 918\n",
      "Step # 919\n",
      "Step # 920\n",
      "Step # 922\n",
      "Step # 923\n",
      "Step # 926\n",
      "Step # 927\n",
      "Step # 928\n",
      "Step # 929\n",
      "Step # 931\n",
      "Step # 932\n",
      "Step # 933\n",
      "Step # 938\n",
      "Step # 939\n",
      "Step # 948\n",
      "Step # 949\n",
      "Step # 950\n",
      "Step # 951\n",
      "Step # 952\n",
      "Step # 953\n",
      "Step # 956\n",
      "Step # 963\n",
      "Step # 969\n",
      "Step # 970\n",
      "Step # 971\n",
      "Step # 974\n",
      "Step # 975\n",
      "Step # 978\n",
      "Step # 979\n",
      "Step # 981\n",
      "Step # 986\n",
      "Step # 989\n",
      "Step # 990\n",
      "Step # 995\n",
      "Step # 997\n",
      "Step # 998\n",
      "Step # 999\n",
      "Step # 1006\n",
      "Step # 1010\n",
      "Step # 1025\n",
      "Step # 1026\n",
      "Step # 1027\n",
      "Step # 1028\n",
      "Step # 1031\n",
      "Step # 1032\n",
      "Step # 1034\n",
      "Step # 1036\n",
      "Step # 1037\n",
      "Step # 1038\n",
      "Step # 1041\n",
      "Step # 1045\n",
      "Step # 1046\n",
      "Step # 1050\n",
      "Step # 1051\n",
      "Step # 1055\n",
      "Step # 1059\n",
      "Step # 1060\n",
      "Step # 1064\n",
      "Step # 1066\n",
      "Step # 1067\n",
      "Step # 1070\n",
      "Step # 1073\n",
      "Step # 1074\n",
      "Step # 1075\n",
      "Step # 1076\n",
      "Step # 1077\n",
      "Step # 1079\n",
      "Step # 1080\n",
      "Step # 1084\n",
      "Step # 1087\n",
      "Step # 1095\n",
      "Step # 1096\n",
      "Step # 1097\n",
      "Step # 1098\n",
      "Step # 1104\n",
      "Step # 1109\n",
      "Step # 1110\n",
      "Step # 1113\n",
      "Step # 1114\n",
      "Step # 1115\n",
      "Step # 1122\n",
      "Step # 1123\n",
      "Step # 1125\n",
      "Step # 1131\n",
      "Step # 1133\n",
      "Step # 1139\n",
      "Step # 1142\n",
      "Step # 1143\n",
      "Step # 1144\n",
      "Step # 1145\n",
      "Step # 1147\n",
      "Step # 1151\n",
      "Step # 1153\n",
      "Step # 1157\n",
      "Step # 1159\n",
      "Step # 1165\n",
      "Step # 1168\n",
      "Step # 1170\n",
      "Step # 1175\n",
      "Step # 1176\n",
      "Step # 1177\n",
      "Step # 1178\n",
      "Step # 1179\n",
      "Step # 1180\n",
      "Step # 1182\n",
      "Step # 1183\n",
      "Step # 1189\n",
      "Step # 1190\n",
      "Step # 1192\n",
      "Step # 1193\n",
      "Step # 1195\n",
      "Step # 1196\n",
      "Step # 1199\n",
      "Step # 1200\n",
      "Step # 1202\n",
      "Step # 1203\n",
      "Step # 1210\n",
      "Step # 1213\n",
      "Step # 1221\n",
      "Step # 1224\n",
      "Step # 1227\n",
      "Step # 1231\n",
      "Step # 1232\n",
      "Step # 1235\n",
      "Step # 1238\n",
      "Step # 1240\n",
      "Step # 1244\n",
      "Step # 1248\n",
      "Step # 1250\n",
      "Step # 1252\n",
      "Step # 1261\n",
      "Step # 1262\n",
      "Step # 1263\n",
      "Step # 1264\n",
      "Step # 1267\n",
      "Step # 1270\n",
      "Step # 1271\n",
      "Step # 1272\n",
      "Step # 1274\n",
      "Step # 1275\n",
      "Step # 1276\n",
      "Step # 1277\n",
      "Step # 1278\n",
      "Step # 1279\n",
      "Step # 1280\n",
      "Step # 1283\n",
      "Step # 1284\n",
      "Step # 1286\n",
      "Step # 1287\n",
      "Step # 1290\n",
      "Step # 1292\n",
      "Step # 1294\n",
      "Step # 1295\n",
      "Step # 1296\n",
      "Step # 1297\n",
      "Step # 1300\n",
      "Step # 1304\n",
      "Step # 1306\n",
      "Step # 1307\n",
      "Step # 1310\n",
      "Step # 1311\n",
      "Step # 1313\n",
      "Step # 1316\n",
      "Step # 1319\n",
      "Step # 1322\n",
      "Step # 1327\n",
      "Step # 1330\n",
      "Step # 1335\n",
      "Step # 1343\n",
      "Step # 1344\n",
      "Step # 1345\n",
      "Step # 1347\n",
      "Step # 1348\n",
      "Step # 1349\n",
      "Step # 1353\n",
      "Step # 1354\n",
      "Step # 1359\n",
      "Step # 1364\n",
      "Step # 1371\n",
      "Step # 1372\n",
      "Step # 1375\n",
      "Step # 1376\n",
      "Step # 1381\n",
      "Step # 1382\n",
      "Step # 1385\n",
      "Step # 1388\n",
      "Step # 1391\n",
      "Step # 1392\n",
      "Step # 1396\n",
      "Step # 1397\n",
      "Step # 1399\n",
      "Step # 1401\n",
      "Step # 1403\n",
      "Step # 1405\n",
      "Step # 1408\n",
      "Step # 1416\n",
      "Step # 1417\n",
      "Step # 1418\n",
      "Step # 1419\n",
      "Step # 1420\n",
      "Step # 1421\n",
      "Step # 1424\n",
      "Step # 1425\n",
      "Step # 1429\n",
      "Step # 1430\n",
      "Step # 1435\n",
      "Step # 1438\n",
      "Step # 1439\n",
      "Step # 1444\n",
      "Step # 1445\n",
      "Step # 1448\n",
      "Step # 1449\n",
      "Step # 1450\n",
      "Step # 1455\n",
      "Step # 1460\n",
      "Step # 1463\n",
      "Step # 1468\n",
      "Step # 1470\n",
      "Step # 1475\n",
      "Step # 1476\n",
      "Step # 1478\n",
      "Step # 1482\n",
      "Step # 1489\n",
      "Step # 1491\n",
      "Step # 1495\n",
      "Step # 1498\n",
      "Step # 1500\n",
      "Step # 1502\n",
      "Step # 1504\n",
      "Step # 1508\n",
      "Step # 1510\n",
      "Step # 1512\n",
      "Step # 1514\n",
      "Step # 1515\n",
      "Step # 1516\n",
      "Step # 1517\n",
      "Step # 1518\n",
      "Step # 1519\n",
      "Step # 1520\n",
      "Step # 1521\n",
      "Step # 1522\n",
      "Step # 1523\n",
      "Step # 1525\n",
      "Step # 1526\n",
      "Step # 1527\n",
      "Step # 1531\n",
      "Step # 1532\n",
      "Step # 1533\n",
      "Step # 1544\n",
      "Step # 1545\n",
      "Step # 1546\n",
      "Step # 1551\n",
      "Step # 1552\n",
      "Step # 1558\n",
      "Step # 1559\n",
      "Step # 1560\n",
      "Step # 1563\n",
      "Step # 1569\n",
      "Step # 1570\n",
      "Step # 1573\n",
      "Step # 1577\n",
      "Step # 1580\n",
      "Step # 1583\n",
      "Step # 1584\n",
      "Step # 1587\n",
      "Step # 1591\n",
      "Step # 1592\n",
      "Step # 1595\n",
      "Step # 1602\n",
      "Step # 1604\n",
      "Step # 1606\n",
      "Step # 1608\n",
      "Step # 1611\n",
      "Step # 1614\n",
      "Step # 1615\n",
      "Step # 1619\n",
      "Step # 1620\n",
      "Step # 1624\n",
      "Step # 1628\n",
      "Step # 1629\n",
      "Step # 1631\n",
      "Step # 1633\n",
      "Step # 1634\n",
      "Step # 1636\n",
      "Step # 1637\n",
      "Step # 1640\n",
      "Step # 1641\n",
      "Step # 1643\n",
      "Step # 1644\n",
      "Step # 1651\n",
      "Step # 1652\n",
      "Step # 1655\n",
      "Step # 1656\n",
      "Step # 1657\n",
      "Step # 1659\n",
      "Step # 1661\n",
      "Step # 1668\n",
      "Step # 1669\n",
      "Step # 1673\n",
      "Step # 1674\n",
      "Step # 1676\n",
      "Step # 1677\n",
      "Step # 1679\n",
      "Step # 1682\n",
      "Step # 1687\n",
      "Step # 1691\n",
      "Step # 1694\n",
      "Step # 1698\n",
      "Step # 1704\n",
      "Step # 1707\n",
      "Step # 1711\n",
      "Step # 1713\n",
      "Step # 1715\n",
      "Step # 1716\n",
      "Step # 1719\n",
      "Step # 1720\n",
      "Step # 1732\n",
      "Step # 1733\n",
      "Step # 1735\n",
      "Step # 1736\n",
      "Step # 1741\n",
      "Step # 1742\n",
      "Step # 1745\n",
      "Step # 1746\n",
      "Step # 1748\n",
      "Step # 1749\n",
      "Step # 1753\n",
      "Step # 1757\n",
      "Step # 1763\n",
      "Step # 1764\n",
      "Step # 1767\n",
      "Step # 1768\n",
      "Step # 1770\n",
      "Step # 1773\n",
      "Step # 1777\n",
      "Step # 1787\n",
      "Step # 1788\n",
      "Step # 1789\n",
      "Step # 1792\n",
      "Step # 1794\n",
      "Step # 1796\n",
      "Step # 1806\n",
      "Step # 1807\n",
      "Step # 1808\n",
      "Step # 1809\n",
      "Step # 1810\n",
      "Step # 1819\n",
      "Step # 1820\n",
      "Step # 1826\n",
      "Step # 1827\n",
      "Step # 1828\n",
      "Step # 1829\n",
      "Step # 1830\n",
      "Step # 1834\n",
      "Step # 1835\n",
      "Step # 1837\n",
      "Step # 1842\n",
      "Step # 1847\n",
      "Step # 1852\n",
      "Step # 1857\n",
      "Step # 1862\n",
      "Step # 1866\n",
      "Step # 1870\n",
      "Step # 1873\n",
      "Step # 1875\n",
      "Step # 1876\n",
      "Step # 1882\n",
      "Step # 1886\n",
      "Step # 1889\n",
      "Step # 1890\n",
      "Step # 1891\n",
      "Step # 1894\n",
      "Step # 1895\n",
      "Step # 1896\n",
      "Step # 1898\n",
      "Step # 1899\n",
      "Step # 1900\n",
      "Step # 1901\n",
      "Step # 1902\n",
      "Step # 1903\n",
      "Step # 1904\n",
      "Step # 1905\n",
      "Step # 1906\n",
      "Step # 1910\n",
      "Step # 1911\n",
      "Step # 1916\n",
      "Step # 1917\n",
      "Step # 1920\n",
      "Step # 1922\n",
      "Step # 1923\n",
      "Step # 1925\n",
      "Step # 1927\n",
      "Step # 1934\n",
      "Step # 1935\n",
      "Step # 1937\n",
      "Step # 1939\n",
      "Step # 1942\n",
      "Step # 1943\n",
      "Step # 1944\n",
      "Step # 1945\n",
      "Step # 1949\n",
      "Step # 1951\n",
      "Step # 1952\n",
      "Step # 1953\n",
      "Step # 1955\n",
      "Step # 1958\n",
      "Step # 1959\n",
      "Step # 1961\n",
      "Step # 1962\n",
      "Step # 1963\n",
      "Step # 1964\n",
      "Step # 1965\n",
      "Step # 1971\n",
      "Step # 1972\n",
      "Step # 1973\n",
      "Step # 1974\n",
      "Step # 1975\n",
      "Step # 1978\n",
      "Step # 1979\n",
      "Step # 1988\n",
      "Step # 1998\n",
      "Step # 1999\n",
      "Step # 2000\n",
      "Step # 2001\n",
      "Step # 2016\n",
      "Step # 2017\n",
      "Step # 2018\n",
      "Step # 2032\n",
      "Step # 2033\n",
      "Step # 2044\n",
      "Step # 2045\n",
      "Step # 2047\n",
      "Step # 2048\n",
      "Step # 2052\n",
      "Step # 2060\n",
      "Step # 2073\n",
      "Step # 2084\n",
      "Step # 2096\n",
      "Step # 2101\n",
      "Step # 2117\n",
      "Step # 2123\n",
      "Step # 2130\n",
      "Step # 2133\n",
      "Step # 2136\n",
      "Step # 2138\n",
      "Step # 2145\n",
      "Step # 2146\n",
      "Step # 2147\n",
      "Step # 2148\n",
      "Step # 2154\n",
      "Step # 2155\n",
      "Step # 2156\n",
      "Step # 2157\n",
      "Step # 2158\n",
      "Step # 2162\n",
      "Step # 2166\n",
      "Step # 2170\n",
      "Step # 2178\n",
      "Step # 2179\n",
      "Step # 2180\n",
      "Step # 2181\n",
      "Step # 2182\n",
      "Step # 2191\n",
      "Step # 2192\n",
      "Step # 2193\n",
      "Step # 2197\n",
      "Step # 2198\n",
      "Step # 2206\n",
      "Step # 2207\n",
      "Step # 2210\n",
      "Step # 2220\n",
      "Step # 2221\n",
      "Step # 2223\n",
      "Step # 2224\n",
      "Step # 2225\n",
      "Step # 2236\n",
      "Step # 2251\n",
      "Step # 2258\n",
      "Step # 2266\n",
      "Step # 2271\n",
      "Step # 2278\n",
      "Step # 2289\n",
      "Step # 2294\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "global policy\n",
    "\n",
    "def run(filename):\n",
    "  global policy\n",
    "\n",
    "  policy = Policy().to(device)\n",
    "  f = torch.load('19_weight_10hr')[\"network state dict\"]\n",
    "  policy.load_state_dict(f)\n",
    "                    \n",
    "  opt = None\n",
    "\n",
    "  agent1 = agent(policy_model(policy))\n",
    "  agent2 = agent(policy_model(policy))\n",
    "  \n",
    "  \n",
    "  learn(\n",
    "      opt = opt,\n",
    "      n_step = 1000000,\n",
    "      gen_episode = gen_episode_by_play(agent1, agent2),\n",
    "      n_epoch = 1,\n",
    "      nsample = 2,\n",
    "      batch_size = 256,\n",
    "      interval_stat = 64,\n",
    "      filename = filename)\n",
    "run(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(100 * np.arange(0,len(loss_list)),np.array(loss_list))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1003aba94e8b49eb6577752c067d2ddea1ccd0c689ae55370a86babf6ba72f76"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
